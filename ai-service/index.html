<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Verification & Liveness Check</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body { font-family: 'Inter', sans-serif; background-color: #f7f9fb; }
        #video, #overlay {
            width: 100%;
            height: 100%;
            position: absolute;
            top: 0;
            left: 0;
            object-fit: cover;
            transform: scaleX(-1);
        }
        #video {
            border-radius: 0.75rem;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }
        #video-container {
            position: relative;
            width: 100%;
            max-width: 400px;
            padding-top: 75%;
            margin: 0 auto;
        }
        #video-container-inner {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            border-left-color: #4f46e5;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
            display: inline-block;
            vertical-align: middle;
            margin-right: 8px;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="p-4 sm:p-8">
    <div class="max-w-4xl mx-auto">
        <h1 class="text-3xl font-bold text-gray-800 mb-6 border-b pb-2">YoTouch Facial Verification System</h1>
        
        <!-- Security Warning Banner -->
        <div id="securityWarning" class="hidden mb-6 bg-yellow-50 border-l-4 border-yellow-400 p-4 rounded">
            <div class="flex">
                <div class="flex-shrink-0">
                    <svg class="h-5 w-5 text-yellow-400" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M8.257 3.099c.765-1.36 2.722-1.36 3.486 0l5.58 9.92c.75 1.334-.213 2.98-1.742 2.98H4.42c-1.53 0-2.493-1.646-1.743-2.98l5.58-9.92zM11 13a1 1 0 11-2 0 1 1 0 012 0zm-1-8a1 1 0 00-1 1v3a1 1 0 002 0V6a1 1 0 00-1-1z" clip-rule="evenodd"/>
                    </svg>
                </div>
                <div class="ml-3">
                    <p class="text-sm text-yellow-700">
                        <strong>Security Notice:</strong> Camera access requires a secure connection (HTTPS) or localhost. If you're seeing errors, please ensure you're accessing this page via HTTPS or run it on a local server.
                    </p>
                </div>
            </div>
        </div>
        
        <div class="grid md:grid-cols-2 gap-8">
            <div class="bg-white p-6 rounded-xl shadow-lg">
                <h2 class="text-xl font-semibold mb-4 text-indigo-600">Step 1: Upload ID Photo</h2>
                
                <input type="file" id="idPhotoInput" accept="image/*" class="w-full text-sm text-gray-500
                    file:mr-4 file:py-2 file:px-4
                    file:rounded-full file:border-0
                    file:text-sm file:font-semibold
                    file:bg-indigo-50 file:text-indigo-700
                    hover:file:bg-indigo-100 mb-4 cursor-pointer"
                >
                <div class="mt-4 p-4 border border-dashed border-gray-300 rounded-lg text-center bg-gray-50">
                    <img id="idPhotoPreview" class="max-h-64 max-w-full mx-auto rounded-lg" style="display: none;">
                    <p id="idPhotoStatus" class="text-sm text-gray-500 mt-2">No photo loaded.</p>
                </div>
            </div>
            <div class="bg-white p-6 rounded-xl shadow-lg">
                <h2 class="text-xl font-semibold mb-4 text-green-600">Step 2: Live Liveness Check</h2>
                <div id="video-container">
                    <div id="video-container-inner">
                        <video id="video" autoplay muted playsinline></video>
                        <canvas id="overlay"></canvas>
                        <div id="cameraPlaceholder" class="absolute inset-0 flex items-center justify-center bg-gray-100 rounded-xl">
                            <div class="text-center p-4">
                                <svg class="w-16 h-16 mx-auto mb-4 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z"></path>
                                </svg>
                                <p class="text-gray-600 mb-4">Camera not activated</p>
                                <button id="activateCameraButton" 
                                        class="bg-blue-500 hover:bg-blue-600 text-white font-semibold py-2 px-6 rounded-lg transition duration-200 shadow-md">
                                    Activate Camera
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="mt-8">
                    <p id="livenessInstruction" class="text-md text-gray-700 font-medium mb-3">
                        Liveness Status: <span id="livenessStatus" class="text-gray-600">Camera not activated</span>
                    </p>
                    <button id="livenessStartButton" 
                            class="w-full bg-green-500 hover:bg-green-600 text-white font-bold py-3 px-4 rounded-lg transition duration-200 shadow-md disabled:opacity-50 disabled:cursor-not-allowed"
                            disabled>
                        Start Liveness & Verification
                    </button>
                </div>
            </div>
        </div>
        <div class="mt-8 bg-indigo-50 p-6 rounded-xl shadow-inner border border-indigo-200">
            <h2 class="text-xl font-semibold mb-4 text-indigo-800">Verification Result</h2>
            <div id="verificationResult" class="text-lg font-bold text-gray-700">
                <p><span class="text-gray-500 font-normal">Matching Score:</span> Awaiting verification...</p>
                <p><span class="text-gray-500 font-normal">Result:</span> Awaiting verification...</p>
            </div>
        </div>
    </div>
    <script>
        const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';
        const MAX_FILE_SIZE_BYTES = 5 * 1024 * 1024;
        
        let TINY_FACE_DETECTOR;
        
        let video, overlay, idPhotoInput, idPhotoPreview, idPhotoStatus, livenessStartButton, livenessStatus, verificationResult, activateCameraButton, cameraPlaceholder;
        let idPhotoDescriptor = null;
        let detectionInterval = null;
        let livenessCheckActive = false;
        let livenessSuccess = false;
        let modelsLoaded = false;
        let cameraActive = false; 
        const DISTANCE_THRESHOLD = 0.6; 
        
        const LIVENESS_DURATION_MS = 3000;
        const MOVEMENT_THRESHOLD = 10;

        function updateStatus(element, message, colorClass, showSpinner = false) {
            element.classList.remove('text-yellow-600', 'text-red-600', 'text-green-600', 'text-indigo-600');
            element.classList.add(colorClass);
            
            let htmlContent = showSpinner ? '<span class="spinner"></span>' : '';
            htmlContent += message;
            element.innerHTML = htmlContent;
        }

        function showMessage(msg, color) {
            verificationResult.innerHTML = `<p><span class="text-gray-500 font-normal">Result:</span> <span class="text-xl font-bold text-${color}-600">${msg}</span></p>`;
        }

        async function loadModels() {
            try {
                updateStatus(livenessStatus, 'Loading AI models...', 'text-yellow-600', true);
                
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
                await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
                
                modelsLoaded = true;
                updateStatus(livenessStatus, 'Models loaded. Click "Activate Camera" to begin.', 'text-green-600');
                console.log('Models loaded.');
            } catch (error) {
                updateStatus(livenessStatus, `ERROR: Failed to load models. ${error.message}`, 'text-red-600');
                console.error('Model loading error:', error);
            }
        }

        async function startVideo() {
            try {
                // Check if getUserMedia is supported
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    throw new Error('Your browser does not support camera access. This feature requires HTTPS or localhost. Please use: Chrome, Firefox, Safari, or Edge on a secure connection (https://).');
                }
                
                updateStatus(livenessStatus, 'Requesting camera access...', 'text-yellow-600', true);
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: { ideal: 400 }, 
                        height: { ideal: 300 },
                        facingMode: 'user'
                    } 
                });
                video.srcObject = stream;
                
                // Wait for video to be ready
                await new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.play();
                        resolve();
                    };
                });
                
                cameraActive = true;
                cameraPlaceholder.style.display = 'none';
                updateStatus(livenessStatus, 'Camera activated successfully!', 'text-green-600');
                console.log('Video started successfully');
            } catch (err) {
                let errorMessage = 'ERROR: Could not access webcam. ';
                
                if (err.message.includes('browser does not support')) {
                    errorMessage = err.message;
                } else if (err.name === 'NotAllowedError' || err.name === 'SecurityError') {
                    errorMessage += 'Camera access was denied. Please allow camera permissions and try again.';
                } else if (err.name === 'NotFoundError') {
                    errorMessage += 'No camera device found on this device.';
                } else if (err.name === 'NotReadableError') {
                    errorMessage += 'Camera is already in use by another application.';
                } else {
                    errorMessage += err.message;
                }
                
                updateStatus(livenessStatus, errorMessage, 'text-red-600');
                showMessage(errorMessage, 'red');
                console.error('Webcam access error:', err);
                activateCameraButton.disabled = false;
                activateCameraButton.textContent = 'Try Again';
            }
        }

        function setupCameraButtonListener() {
            activateCameraButton.addEventListener('click', async () => {
                if (!modelsLoaded) {
                    updateStatus(livenessStatus, 'Please wait, models are still loading...', 'text-yellow-600');
                    return;
                }
                activateCameraButton.disabled = true;
                activateCameraButton.textContent = 'Activating...';
                await startVideo();
            });
        }

        function setupPhotoInputListener() {
            idPhotoInput.addEventListener('change', async (event) => {
                if (!modelsLoaded) {
                    updateStatus(idPhotoStatus, 'ERROR: Models not loaded yet.', 'text-red-600');
                    livenessStartButton.disabled = true;
                    return;
                }
                if (detectionInterval) clearInterval(detectionInterval); 
                idPhotoDescriptor = null;
                
                const file = event.target.files[0];
                if (!file) {
                    updateStatus(idPhotoStatus, 'No photo loaded.', 'text-gray-500');
                    idPhotoPreview.style.display = 'none';
                    livenessStartButton.disabled = true;
                    return;
                }

                if (file.size > MAX_FILE_SIZE_BYTES) {
                    updateStatus(idPhotoStatus, `ERROR: File size exceeds ${(MAX_FILE_SIZE_BYTES / 1024 / 1024)}MB limit.`, 'text-red-600');
                    idPhotoPreview.style.display = 'none';
                    livenessStartButton.disabled = true;
                    return;
                }

                updateStatus(idPhotoStatus, 'Processing photo...', 'text-indigo-600', true);
                verificationResult.innerHTML = '<p><span class="text-gray-500 font-normal">Matching Score:</span> Awaiting verification...</p><p><span class="text-gray-500 font-normal">Result:</span> Awaiting verification...</p>';

                try {
                    const reader = new FileReader();
                    reader.onload = function(e) {
                        idPhotoPreview.src = e.target.result;
                        idPhotoPreview.style.display = 'block';
                    };
                    reader.readAsDataURL(file);

                    const img = await faceapi.bufferToImage(file);
                    
                    const detection = await faceapi.detectSingleFace(img, TINY_FACE_DETECTOR)
                        .withFaceLandmarks()
                        .withFaceDescriptor();

                    if (detection) {
                        idPhotoDescriptor = detection.descriptor;
                        updateStatus(idPhotoStatus, 'ID Photo detected and ready for verification.', 'text-green-600');
                        
                        if (cameraActive && video.readyState >= 2) {
                            updateStatus(livenessStatus, 'Ready to start verification.', 'text-green-600');
                            livenessStartButton.disabled = false;
                        } else if (!cameraActive) {
                            updateStatus(livenessStatus, 'Please activate your camera to continue.', 'text-yellow-600');
                        }
                        
                    } else {
                        updateStatus(idPhotoStatus, 'ERROR: No face detected in the uploaded photo. Try a clearer image.', 'text-red-600');
                        livenessStartButton.disabled = true;
                    }
                } catch (e) {
                    updateStatus(idPhotoStatus, `ERROR during photo processing: ${e.message}`, 'text-red-600');
                    livenessStartButton.disabled = true;
                    console.error('ID Photo processing error:', e);
                }
            });
        }
        
        function setupVideoListener() {
            video.addEventListener('play', () => {
                console.log('Video play event triggered');
                const displaySize = { width: video.offsetWidth, height: video.offsetHeight };
                faceapi.matchDimensions(overlay, displaySize);

                if (idPhotoDescriptor) {
                    updateStatus(livenessStatus, 'Webcam active. Ready to start verification.', 'text-green-600');
                    livenessStartButton.disabled = false;
                } else {
                    updateStatus(livenessStatus, 'Webcam active. Please upload your ID photo.', 'text-yellow-600');
                }

                detectionInterval = setInterval(async () => {
                    if (!video.srcObject || !modelsLoaded) return;
                    
                    try {
                        const detections = await faceapi.detectAllFaces(video, TINY_FACE_DETECTOR)
                            .withFaceLandmarks()
                            .withFaceDescriptors();
                        
                        const resizedDetections = faceapi.resizeResults(detections, displaySize);
                        
                        overlay.getContext('2d').clearRect(0, 0, overlay.width, overlay.height);
                        faceapi.draw.drawDetections(overlay, resizedDetections);
                        faceapi.draw.drawFaceLandmarks(overlay, resizedDetections);

                        if (!livenessCheckActive) {
                            if (idPhotoDescriptor) {
                                if (resizedDetections.length === 0) {
                                    updateStatus(livenessStatus, 'Move closer and look at the camera.', 'text-yellow-600');
                                    livenessStartButton.disabled = true;
                                } else {
                                    updateStatus(livenessStatus, 'Webcam active. Ready to start verification.', 'text-green-600');
                                    livenessStartButton.disabled = false;
                                }
                            }
                        }
                    } catch (e) {
                        console.error("Error during continuous detection:", e);
                        clearInterval(detectionInterval);
                        updateStatus(livenessStatus, 'Detection stopped due to error.', 'text-red-600');
                    }
                }, 100);
            });
            
            // Fallback: manually trigger if video is already playing
            if (video.readyState >= 2) {
                console.log('Video already ready, manually triggering setup');
                const displaySize = { width: video.offsetWidth, height: video.offsetHeight };
                faceapi.matchDimensions(overlay, displaySize);
                
                if (idPhotoDescriptor) {
                    updateStatus(livenessStatus, 'Webcam active. Ready to start verification.', 'text-green-600');
                    livenessStartButton.disabled = false;
                } else {
                    updateStatus(livenessStatus, 'Webcam active. Please upload your ID photo.', 'text-yellow-600');
                }
                
                if (!detectionInterval) {
                    detectionInterval = setInterval(async () => {
                        if (!video.srcObject || !modelsLoaded) return;
                        
                        try {
                            const detections = await faceapi.detectAllFaces(video, TINY_FACE_DETECTOR)
                                .withFaceLandmarks()
                                .withFaceDescriptors();
                            
                            const resizedDetections = faceapi.resizeResults(detections, displaySize);
                            
                            overlay.getContext('2d').clearRect(0, 0, overlay.width, overlay.height);
                            faceapi.draw.drawDetections(overlay, resizedDetections);
                            faceapi.draw.drawFaceLandmarks(overlay, resizedDetections);

                            if (!livenessCheckActive) {
                                if (idPhotoDescriptor) {
                                    if (resizedDetections.length === 0) {
                                        updateStatus(livenessStatus, 'Move closer and look at the camera.', 'text-yellow-600');
                                        livenessStartButton.disabled = true;
                                    } else {
                                        updateStatus(livenessStatus, 'Webcam active. Ready to start verification.', 'text-green-600');
                                        livenessStartButton.disabled = false;
                                    }
                                }
                            }
                        } catch (e) {
                            console.error("Error during continuous detection:", e);
                            clearInterval(detectionInterval);
                            updateStatus(livenessStatus, 'Detection stopped due to error.', 'text-red-600');
                        }
                    }, 100);
                }
            }
        }

        function setupLivenessButtonListener() {
            livenessStartButton.addEventListener('click', async () => {
                if (!idPhotoDescriptor) {
                    showMessage("Please upload a valid ID photo first.", 'red');
                    return;
                }
                if (livenessCheckActive) return;

                livenessStartButton.disabled = true;
                livenessCheckActive = true;
                livenessSuccess = false;
                let finalLiveDescriptor = null;
                
                updateStatus(livenessStatus, 'Liveness Check: Please gently shake your head YES/NO for 3 seconds.', 'text-indigo-600');
                
                const liveDetectionResults = [];
                const startTime = Date.now();
                let lastX = null;
                let totalMovement = 0;

                const livenessTimer = setInterval(async () => {
                    const elapsed = Date.now() - startTime;
                    const remaining = Math.ceil((LIVENESS_DURATION_MS - elapsed) / 1000);
                    
                    if (elapsed >= LIVENESS_DURATION_MS) {
                        clearInterval(livenessTimer);
                        
                        if (totalMovement > MOVEMENT_THRESHOLD * 5) {
                            livenessSuccess = true;
                            updateStatus(livenessStatus, 'Liveness Check SUCCESS.', 'text-green-600');
                        } else {
                            updateStatus(livenessStatus, 'Liveness Check FAILED: Insufficient movement. Try again.', 'text-red-600');
                        }

                        if (livenessSuccess) {
                            if (liveDetectionResults.length > 0) {
                                finalLiveDescriptor = liveDetectionResults[liveDetectionResults.length - 1];
                                await verifyFace(finalLiveDescriptor);
                            } else {
                                showMessage("Liveness failed: Face lost during check.", 'red');
                            }
                        } else {
                            showMessage("Verification failed due to Liveness Check failure.", 'red');
                        }

                        livenessCheckActive = false;
                        livenessStartButton.disabled = false;
                        return;
                    }

                    const detections = await faceapi.detectSingleFace(video, TINY_FACE_DETECTOR)
                        .withFaceLandmarks()
                        .withFaceDescriptor();

                    if (detections) {
                        liveDetectionResults.push(detections.descriptor);
                        
                        const currentX = detections.detection.box.x;
                        if (lastX !== null) {
                            totalMovement += Math.abs(currentX - lastX);
                        }
                        lastX = currentX;
                        updateStatus(livenessStatus, `Liveness Check: Shake your head (Time left: ${remaining}s)`, 'text-indigo-600');
                    } else {
                        updateStatus(livenessStatus, `Liveness Check: Keep your face visible! (Time left: ${remaining}s)`, 'text-red-600');
                    }
                }, 200);
            });
        }

        async function verifyFace(liveDescriptor) {
            updateStatus(livenessStatus, 'Performing facial recognition...', 'text-indigo-600', true);
            if (!liveDescriptor || !idPhotoDescriptor) {
                showMessage("Verification failed: Missing face data.", 'red');
                return;
            }
            
            try {
                const distance = faceapi.euclideanDistance(idPhotoDescriptor, liveDescriptor);
                const isMatch = distance < DISTANCE_THRESHOLD;
                const scoreText = distance.toFixed(4);
                let resultText = '';
                let colorClass = 'text-red-600';

                if (isMatch) {
                    resultText = 'VERIFIED! The faces match.';
                    colorClass = 'text-green-600';
                } else {
                    resultText = 'FAILED. The faces DO NOT match.';
                    colorClass = 'text-red-600';
                }

                verificationResult.innerHTML = `<p><span class="text-gray-500 font-normal">Matching Score (Distance):</span> <span class="${colorClass}">${scoreText}</span> (Threshold: ${DISTANCE_THRESHOLD})</p><p><span class="text-gray-500 font-normal">Result:</span> <span class="text-2xl font-bold ${colorClass}">${resultText}</span></p>`;
                
                updateStatus(livenessStatus, 'Verification complete.', 'text-green-600');
            } catch (e) {
                console.error("Error during verification:", e);
                showMessage("Verification failed due to a critical error.", 'red');
                updateStatus(livenessStatus, 'Verification failed.', 'text-red-600');
            }
        }

        async function main() {
            try {
                if (typeof faceapi === 'undefined') {
                    console.warn("face-api.js library not yet loaded. Retrying...");
                    setTimeout(main, 200); 
                    return;
                }

                video = document.getElementById('video');
                overlay = document.getElementById('overlay');
                idPhotoInput = document.getElementById('idPhotoInput');
                idPhotoPreview = document.getElementById('idPhotoPreview');
                idPhotoStatus = document.getElementById('idPhotoStatus');
                livenessStartButton = document.getElementById('livenessStartButton');
                livenessStatus = document.getElementById('livenessStatus');
                verificationResult = document.getElementById('verificationResult');
                activateCameraButton = document.getElementById('activateCameraButton');
                cameraPlaceholder = document.getElementById('cameraPlaceholder');
                
                TINY_FACE_DETECTOR = new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 });

                updateStatus(livenessStatus, 'Loading AI models...', 'text-yellow-600', true);
                
                // Check browser compatibility
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    document.getElementById('securityWarning').classList.remove('hidden');
                    updateStatus(livenessStatus, 'Camera not supported. See warning above.', 'text-red-600');
                    activateCameraButton.disabled = true;
                    activateCameraButton.textContent = 'Camera Not Supported';
                    activateCameraButton.classList.add('bg-gray-400', 'hover:bg-gray-400');
                    activateCameraButton.classList.remove('bg-blue-500', 'hover:bg-blue-600');
                }
                
                await loadModels();
                
                setupCameraButtonListener();
                setupPhotoInputListener();
                setupVideoListener();
                setupLivenessButtonListener();
            } catch (e) {
                console.error("Fatal initialization error:", e);
                updateStatus(livenessStatus, `FATAL ERROR during startup: ${e.message}`, 'text-red-600');
            }
        }

        window.addEventListener('load', main);
    </script>
</body>
</html>